{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H-Voice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\anany\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 4109 images belonging to 2 classes.\n",
      "Found 1728 images belonging to 2 classes.\n",
      "Found 836 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# ---------- Format training set ---------- #\n",
    "train_dir = 'E:\\DL-project\\Data\\H-Voice\\Training_Set'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,        # Normalize pixel values to [0, 1]\n",
    "    horizontal_flip=True,  # Enable horizontal flip augmentation for training data\n",
    ")\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "train_generator_HVoice = train_datagen.flow_from_directory(\n",
    "    train_dir,              # Path to the training directory\n",
    "    target_size=(150, 150), # Resize images to 150x150 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='binary'     # Assuming binary classification\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- Format validation set ---------- #\n",
    "validation_dir = 'E:\\DL-project\\Data\\H-Voice\\Validation_Set'\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",
    ")\n",
    "\n",
    "# Flow validation images in batches of 32 using valid_datagen generator\n",
    "valid_generator_HVoice = valid_datagen.flow_from_directory(\n",
    "    validation_dir,         # Path to the validation directory\n",
    "    target_size=(150, 150), # Resize images to 150x150 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='binary'     # Assuming binary classification\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- Format test set ---------- #\n",
    "test_dir = 'E:\\DL-project\\Data\\H-Voice\\Test_Set'\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",
    ")\n",
    "\n",
    "# Flow validation images in batches of 32 using valid_datagen generator\n",
    "test_generator_HVoice = test_datagen.flow_from_directory(\n",
    "    test_dir,         # Path to the validation directory\n",
    "    target_size=(150, 150), # Resize images to 150x150 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='binary'     # Assuming binary classification\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SiF-DeepVC - Regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7030 images belonging to 2 classes.\n",
      "Found 1357 images belonging to 2 classes.\n",
      "Found 1350 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# ---------- Format training set ---------- #\n",
    "train_dir = 'E:\\DL-project\\Data\\SiF-DeepVC\\Training_Set'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,        # Normalize pixel values to [0, 1]\n",
    "    horizontal_flip=True,  # Enable horizontal flip augmentation for training data\n",
    ")\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "train_generator_SiF_reg = train_datagen.flow_from_directory(\n",
    "    train_dir,              # Path to the training directory\n",
    "    target_size=(150, 150), # Resize images to 150x150 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='binary'     # Assuming binary classification\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- Format validation set ---------- #\n",
    "validation_dir = 'E:\\DL-project\\Data\\SiF-DeepVC\\Validation_Set'\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",
    ")\n",
    "\n",
    "# Flow validation images in batches of 32 using valid_datagen generator\n",
    "valid_generator_SiF_reg = valid_datagen.flow_from_directory(\n",
    "    validation_dir,         # Path to the validation directory\n",
    "    target_size=(150, 150), # Resize images to 150x150 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='binary'     # Assuming binary classification\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- Format test set ---------- #\n",
    "test_dir = 'E:\\DL-project\\Data\\SiF-DeepVC\\Test_Set'\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",
    ")\n",
    "\n",
    "# Flow validation images in batches of 32 using valid_datagen generator\n",
    "test_generator_SiF_reg = test_datagen.flow_from_directory(\n",
    "    test_dir,         # Path to the validation directory\n",
    "    target_size=(150, 150), # Resize images to 150x150 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='binary'     # Assuming binary classification\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- Format deep4s test set ---------- #\n",
    "deep4s_dir = 'E:\\DL-project\\Data\\SiF-DeepVC\\Deep4SNet_Target_Test_Set'\n",
    "\n",
    "deep4s_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",
    ")\n",
    "\n",
    "# Flow validation images in batches of 32 using valid_datagen generator\n",
    "deep4s_generator_SiF_reg = deep4s_datagen.flow_from_directory(\n",
    "    deep4s_dir,         # Path to the validation directory\n",
    "    target_size=(150, 150), # Resize images to 150x150 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='binary'     # Assuming binary classification\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SiF-DeepVC - Filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6303 images belonging to 2 classes.\n",
      "Found 1351 images belonging to 2 classes.\n",
      "Found 1350 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# ---------- Format training set ---------- #\n",
    "train_dir = 'E:\\DL-project\\Data\\SiF-DeepVC\\Training_Set_Filtered'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,        # Normalize pixel values to [0, 1]\n",
    "    horizontal_flip=True,  # Enable horizontal flip augmentation for training data\n",
    ")\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "train_generator_SiF_filtered = train_datagen.flow_from_directory(\n",
    "    train_dir,              # Path to the training directory\n",
    "    target_size=(150, 150), # Resize images to 150x150 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='binary'     # Assuming binary classification\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- Format validation set ---------- #\n",
    "validation_dir = 'E:\\DL-project\\Data\\SiF-DeepVC\\Validation_Set_Filtered'\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",
    ")\n",
    "\n",
    "# Flow validation images in batches of 32 using valid_datagen generator\n",
    "valid_generator_SiF_filtered = valid_datagen.flow_from_directory(\n",
    "    validation_dir,         # Path to the validation directory\n",
    "    target_size=(150, 150), # Resize images to 150x150 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='binary'     # Assuming binary classification\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- Format test set ---------- #\n",
    "test_dir = 'E:\\DL-project\\Data\\SiF-DeepVC\\Test_Set_Filtered'\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",
    ")\n",
    "\n",
    "# Flow validation images in batches of 32 using valid_datagen generator\n",
    "test_generator_SiF_filtered = test_datagen.flow_from_directory(\n",
    "    test_dir,         # Path to the validation directory\n",
    "    target_size=(150, 150), # Resize images to 150x150 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='binary'     # Assuming binary classification\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- Format deep4s test set ---------- #\n",
    "deep4s_dir = 'E:\\DL-project\\Data\\SiF-DeepVC\\Deep4SNet_Target_Test_Set_Filtered'\n",
    "\n",
    "deep4s_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",
    ")\n",
    "\n",
    "# Flow validation images in batches of 32 using valid_datagen generator\n",
    "deep4s_generator_SiF_filtered = deep4s_datagen.flow_from_directory(\n",
    "    deep4s_dir,         # Path to the validation directory\n",
    "    target_size=(150, 150), # Resize images to 150x150 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='binary'     # Assuming binary classification\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H-Voice + SiF-DeepVC - Regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8300 images belonging to 2 classes.\n",
      "Found 3078 images belonging to 2 classes.\n",
      "Found 2186 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# ---------- Format training set ---------- #\n",
    "train_dir = 'E:\\DL-project\\Data\\H-Voice_SiF-Regular\\Training_Set'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,        # Normalize pixel values to [0, 1]\n",
    "    horizontal_flip=True,  # Enable horizontal flip augmentation for training data\n",
    ")\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "train_generator_HVoice_SiF_Reg = train_datagen.flow_from_directory(\n",
    "    train_dir,              # Path to the training directory\n",
    "    target_size=(150, 150), # Resize images to 150x150 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='binary'     # Assuming binary classification\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- Format validation set ---------- #\n",
    "validation_dir = 'E:\\DL-project\\Data\\H-Voice_SiF-Regular\\Validation_Set'\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",
    ")\n",
    "\n",
    "# Flow validation images in batches of 32 using valid_datagen generator\n",
    "valid_generator_HVoice_SiF_Reg = valid_datagen.flow_from_directory(\n",
    "    validation_dir,         # Path to the validation directory\n",
    "    target_size=(150, 150), # Resize images to 150x150 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='binary'     # Assuming binary classification\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- Format test set ---------- #\n",
    "test_dir = 'E:\\DL-project\\Data\\H-Voice_SiF-Regular\\Test_Set'\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",
    ")\n",
    "\n",
    "# Flow validation images in batches of 32 using valid_datagen generator\n",
    "test_generator_HVoice_SiF_Reg = test_datagen.flow_from_directory(\n",
    "    test_dir,         # Path to the validation directory\n",
    "    target_size=(150, 150), # Resize images to 150x150 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='binary'     # Assuming binary classification\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H-Voice + SiF-DeepVC (Filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8357 images belonging to 2 classes.\n",
      "Found 3078 images belonging to 2 classes.\n",
      "Found 2186 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# ---------- Format training set ---------- #\n",
    "train_dir = 'E:\\DL-project\\Data\\H-Voice_SiF-Filtered\\Training_Set'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,        # Normalize pixel values to [0, 1]\n",
    "    horizontal_flip=True,  # Enable horizontal flip augmentation for training data\n",
    ")\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "train_generator_HVoice_SiF_Filtered = train_datagen.flow_from_directory(\n",
    "    train_dir,              # Path to the training directory\n",
    "    target_size=(150, 150), # Resize images to 150x150 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='binary'     # Assuming binary classification\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- Format validation set ---------- #\n",
    "validation_dir = 'E:\\DL-project\\Data\\H-Voice_SiF-Filtered\\Validation_Set'\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",
    ")\n",
    "\n",
    "# Flow validation images in batches of 32 using valid_datagen generator\n",
    "valid_generator_HVoice_SiF_Filtered = valid_datagen.flow_from_directory(\n",
    "    validation_dir,         # Path to the validation directory\n",
    "    target_size=(150, 150), # Resize images to 150x150 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='binary'     # Assuming binary classification\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- Format test set ---------- #\n",
    "test_dir = 'E:\\DL-project\\Data\\H-Voice_SiF-Filtered\\Test_Set'\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1] for validation data\n",
    ")\n",
    "\n",
    "# Flow validation images in batches of 32 using valid_datagen generator\n",
    "test_generator_HVoice_SiF_Filtered = test_datagen.flow_from_directory(\n",
    "    test_dir,         # Path to the validation directory\n",
    "    target_size=(150, 150), # Resize images to 150x150 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='binary'     # Assuming binary classification\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling (ONLY RUN ONCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run once to save the models as keras files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Define the Deep4SNet CNN model\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape, kernel_initializer='random_normal', bias_initializer='zeros'),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n",
    "\n",
    "        Conv2D(32, (3, 3), strides=(1, 1), activation='relu'),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n",
    "\n",
    "        Conv2D(64, (3, 3), strides=(1, 1), activation='relu'),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='sigmoid')  # Output layer\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Adjusted model with increased depth and dropout rates\n",
    "def increased_dropout(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape, kernel_initializer='random_normal', bias_initializer='zeros'),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n",
    "        Dropout(0.3),  # Increased dropout rate\n",
    "\n",
    "        Conv2D(64, (3, 3), strides=(1, 1), activation='relu'),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n",
    "        Dropout(0.4),  # Increased dropout rate\n",
    "\n",
    "        Conv2D(128, (3, 3), strides=(1, 1), activation='relu'),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n",
    "        Dropout(0.4),  # Increased dropout rate\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),  # Keep dropout rate for the dense layer\n",
    "        Dense(num_classes, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Adjusted model with increased depth\n",
    "def deeper_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape, kernel_initializer='random_normal', bias_initializer='zeros'),\n",
    "        Conv2D(32, (3, 3), strides=(1, 1), activation='relu'),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n",
    "\n",
    "        Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "        Conv2D(64, (3, 3), strides=(1, 1), activation='relu'),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n",
    "\n",
    "        Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "        Conv2D(128, (3, 3), strides=(1, 1), activation='relu'),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2), padding='valid'),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original - H-Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n",
      "Keras version: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path = 'E:\\DL-project\\Models\\Deep4SNet-Original-HVoice\\model_Deep4SNet.h5'\n",
    "weights_path = 'E:\\DL-project\\Models\\Deep4SNet-Original-HVoice\\weights_Deep4SNet.h5'\n",
    "\n",
    "model_original_HVoice = load_model(model_path)\n",
    "model_original_HVoice.load_weights(weights_path)\n",
    "\n",
    "# Save as keras model for moving between computers\n",
    "model_original_HVoice.save('E:\\DL-project\\Models\\Deep4SNet-Original-HVoice.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our - H-Voice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closest imitation to the loaded original model\n",
    "Trained on H-Voice histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\anany\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\anany\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "129/129 [==============================] - 47s 353ms/step - loss: 0.7168 - accuracy: 0.5062\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 19s 149ms/step - loss: 0.6938 - accuracy: 0.5135\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 21s 161ms/step - loss: 0.6931 - accuracy: 0.5079\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 21s 164ms/step - loss: 0.6931 - accuracy: 0.5084\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 21s 165ms/step - loss: 0.6930 - accuracy: 0.5084\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 21s 163ms/step - loss: 0.6931 - accuracy: 0.5084\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 20s 157ms/step - loss: 0.6930 - accuracy: 0.5084\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 23s 177ms/step - loss: 0.6930 - accuracy: 0.5084\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 22s 169ms/step - loss: 0.6931 - accuracy: 0.5084\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 22s 173ms/step - loss: 0.6930 - accuracy: 0.5084\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 150, 150, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 75, 75, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 73, 73, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 17, 17, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18496)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1183808   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1212513 (4.63 MB)\n",
      "Trainable params: 1212513 (4.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model params\n",
    "input_shape = (150, 150, 3)\n",
    "num_classes = 1 # Number of outputs per input\n",
    "\n",
    "# Model trained on training set\n",
    "model_our_HVoice = create_cnn_model(input_shape, num_classes)\n",
    "model_our_HVoice.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model_our_HVoice.fit(train_generator_HVoice, epochs=10)\n",
    "model_our_HVoice.summary()  # Print model summary\n",
    "\n",
    "# Save model\n",
    "model_dir ='E:\\DL-project\\Models\\Deep4SNet-Our-HVoice.keras'\n",
    "#if not os.path.exists(model_dir):\n",
    "#    os.makedirs(model_dir)\n",
    "model_our_HVoice.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our - H-Voice - Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "129/129 [==============================] - 50s 384ms/step - loss: 0.8273 - accuracy: 0.5133\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 52s 404ms/step - loss: 0.6948 - accuracy: 0.4819\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 60s 467ms/step - loss: 0.6940 - accuracy: 0.5009\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 48s 372ms/step - loss: 0.6938 - accuracy: 0.5035\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 49s 375ms/step - loss: 0.6885 - accuracy: 0.5354\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 52s 400ms/step - loss: 0.6276 - accuracy: 0.6444\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 49s 379ms/step - loss: 0.4976 - accuracy: 0.7673\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 47s 363ms/step - loss: 0.3916 - accuracy: 0.8377\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 46s 357ms/step - loss: 0.3163 - accuracy: 0.8812\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 51s 397ms/step - loss: 0.2788 - accuracy: 0.8983\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 75, 75, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 73, 73, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 36, 36, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 36, 36, 64)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 17, 17, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 17, 17, 128)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 36992)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               4735104   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4847809 (18.49 MB)\n",
      "Trainable params: 4847809 (18.49 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# H-Voice\n",
    "input_shape = (150, 150, 3)\n",
    "num_classes = 1 # Number of outputs per input\n",
    "\n",
    "# Model trained on training set\n",
    "H_voice_drop = increased_dropout(input_shape, num_classes)\n",
    "H_voice_drop.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "H_voice_drop.fit(train_generator_HVoice, epochs=10)\n",
    "H_voice_drop.summary()  # Print model summary\n",
    "H_voice_drop.save('E:\\DL-project\\Models\\Deep4SNet-Our-HVoice-Dropout.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our - H-Voice - Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "129/129 [==============================] - 59s 451ms/step - loss: 0.6972 - accuracy: 0.5125\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 56s 430ms/step - loss: 0.6937 - accuracy: 0.4979\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 60s 463ms/step - loss: 0.6935 - accuracy: 0.4962\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 59s 457ms/step - loss: 0.6935 - accuracy: 0.5094\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 59s 457ms/step - loss: 0.6933 - accuracy: 0.5060\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 55s 422ms/step - loss: 0.6931 - accuracy: 0.5074\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 59s 459ms/step - loss: 0.6931 - accuracy: 0.5013\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 58s 453ms/step - loss: 0.6931 - accuracy: 0.5082\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 58s 450ms/step - loss: 0.6931 - accuracy: 0.5084\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 59s 454ms/step - loss: 0.6930 - accuracy: 0.5062\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 150, 150, 32)      896       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 148, 148, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 74, 74, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 74, 74, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 72, 72, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 36, 36, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 36, 36, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 34, 34, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 17, 17, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 36992)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               9470208   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9757473 (37.22 MB)\n",
      "Trainable params: 9757473 (37.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# H-Voice\n",
    "input_shape = (150, 150, 3)\n",
    "num_classes = 1 # Number of outputs per input\n",
    "\n",
    "# Model trained on training set\n",
    "H_voice_deep = deeper_model(input_shape, num_classes)\n",
    "H_voice_deep.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "H_voice_deep.fit(train_generator_HVoice, epochs=10)\n",
    "H_voice_deep.summary()  # Print model summary\n",
    "H_voice_deep.save('E:\\DL-project\\Models\\Deep4SNet-Our-HVoice-Deep.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our - SiF-DeepVC - Filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "197/197 [==============================] - 71s 357ms/step - loss: 0.6030 - accuracy: 0.6678\n",
      "Epoch 2/10\n",
      "197/197 [==============================] - 32s 164ms/step - loss: 0.3472 - accuracy: 0.8599\n",
      "Epoch 3/10\n",
      "197/197 [==============================] - 32s 163ms/step - loss: 0.2570 - accuracy: 0.9035\n",
      "Epoch 4/10\n",
      "197/197 [==============================] - 30s 154ms/step - loss: 0.2248 - accuracy: 0.9175\n",
      "Epoch 5/10\n",
      "197/197 [==============================] - 31s 155ms/step - loss: 0.1901 - accuracy: 0.9311\n",
      "Epoch 6/10\n",
      "197/197 [==============================] - 30s 150ms/step - loss: 0.1918 - accuracy: 0.9318\n",
      "Epoch 7/10\n",
      "197/197 [==============================] - 31s 159ms/step - loss: 0.1777 - accuracy: 0.9402\n",
      "Epoch 8/10\n",
      "197/197 [==============================] - 32s 162ms/step - loss: 0.1642 - accuracy: 0.9448\n",
      "Epoch 9/10\n",
      "197/197 [==============================] - 36s 181ms/step - loss: 0.1606 - accuracy: 0.9424\n",
      "Epoch 10/10\n",
      "197/197 [==============================] - 32s 165ms/step - loss: 0.1564 - accuracy: 0.9472\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 150, 150, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPooli  (None, 75, 75, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 73, 73, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPooli  (None, 36, 36, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPooli  (None, 17, 17, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 18496)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                1183808   \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1212513 (4.63 MB)\n",
      "Trainable params: 1212513 (4.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model params\n",
    "input_shape = (150, 150, 3)\n",
    "num_classes = 1 # Number of outputs per input\n",
    "\n",
    "# Model trained on training set\n",
    "model_our_SiF_filtered = create_cnn_model(input_shape, num_classes)\n",
    "model_our_SiF_filtered.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model_our_SiF_filtered.fit(train_generator_SiF_filtered, epochs=10)\n",
    "model_our_SiF_filtered.summary()  # Print model summary\n",
    "\n",
    "# Save model\n",
    "model_dir = 'E:\\DL-project\\Models\\Deep4SNet-Our-SiF-Filtered.keras'\n",
    "#if not os.path.exists(model_dir):\n",
    "#    os.makedirs(model_dir)\n",
    "model_our_SiF_filtered.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our - SiF-DeepVC - Regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "220/220 [==============================] - 80s 363ms/step - loss: 0.5591 - accuracy: 0.6969\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 39s 177ms/step - loss: 0.3455 - accuracy: 0.8619\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 38s 174ms/step - loss: 0.2560 - accuracy: 0.9013\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 37s 166ms/step - loss: 0.2073 - accuracy: 0.9235\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 36s 164ms/step - loss: 0.1899 - accuracy: 0.9313\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 36s 161ms/step - loss: 0.1815 - accuracy: 0.9334\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 34s 153ms/step - loss: 0.1738 - accuracy: 0.9367\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 35s 157ms/step - loss: 0.1630 - accuracy: 0.9400\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 34s 156ms/step - loss: 0.1569 - accuracy: 0.9444\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 39s 178ms/step - loss: 0.1474 - accuracy: 0.9468\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 150, 150, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPooli  (None, 75, 75, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 73, 73, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPooli  (None, 36, 36, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPooli  (None, 17, 17, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 18496)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                1183808   \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1212513 (4.63 MB)\n",
      "Trainable params: 1212513 (4.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model params\n",
    "input_shape = (150, 150, 3)\n",
    "num_classes = 1 # Number of outputs per input\n",
    "\n",
    "# Model trained on training set\n",
    "model_our_SiF_regular = create_cnn_model(input_shape, num_classes)\n",
    "model_our_SiF_regular.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model_our_SiF_regular.fit(train_generator_SiF_reg, epochs=10)\n",
    "model_our_SiF_regular.summary()  # Print model summary\n",
    "model_our_SiF_regular.save('E:\\DL-project\\Models\\Deep4SNet-Our-SiF-Regular.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our - SiF-DeepVC - Regular - Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular SiF\n",
    "input_shape = (150, 150, 3)\n",
    "num_classes = 1 # Number of outputs per input\n",
    "\n",
    "# Model trained on training set\n",
    "sif_reg_drop = increased_dropout(input_shape, num_classes)\n",
    "sif_reg_drop.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "sif_reg_drop.fit(train_generator_SiF_reg, epochs=10)\n",
    "sif_reg_drop.summary()  # Print model summary\n",
    "sif_reg_drop.save('E:\\DL-project\\Models\\Deep4SNet-Our-SiF-Regular-Dropout.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our - SiF-DeepVC - Regular - Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "220/220 [==============================] - 99s 446ms/step - loss: 0.6416 - accuracy: 0.5945\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 95s 429ms/step - loss: 0.4658 - accuracy: 0.7898\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 97s 438ms/step - loss: 0.3483 - accuracy: 0.8528\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 95s 429ms/step - loss: 0.2655 - accuracy: 0.8963\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 95s 433ms/step - loss: 0.2114 - accuracy: 0.9229\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 98s 446ms/step - loss: 0.1854 - accuracy: 0.9326\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 92s 419ms/step - loss: 0.1744 - accuracy: 0.9356\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 96s 437ms/step - loss: 0.1619 - accuracy: 0.9417\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 95s 433ms/step - loss: 0.1562 - accuracy: 0.9455\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 94s 425ms/step - loss: 0.1475 - accuracy: 0.9488\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_27 (Conv2D)          (None, 150, 150, 32)      896       \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 148, 148, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPooli  (None, 74, 74, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 74, 74, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 72, 72, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPooli  (None, 36, 36, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 36, 36, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 34, 34, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPooli  (None, 17, 17, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 36992)             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 256)               9470208   \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9757473 (37.22 MB)\n",
      "Trainable params: 9757473 (37.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# SiF Regular\n",
    "input_shape = (150, 150, 3)\n",
    "num_classes = 1 # Number of outputs per input\n",
    "\n",
    "# Model trained on training set\n",
    "sif_reg_deep = deeper_model(input_shape, num_classes)\n",
    "sif_reg_deep.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "sif_reg_deep.fit(train_generator_SiF_reg, epochs=10)\n",
    "sif_reg_deep.summary()  # Print model summary\n",
    "sif_reg_deep.save('E:\\DL-project\\Models\\Deep4SNet-Our-SiF-Regular-Deep.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our - H-Voice + SiF-DeepVC - Regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "260/260 [==============================] - 94s 359ms/step - loss: 0.5160 - accuracy: 0.7082\n",
      "Epoch 2/10\n",
      "260/260 [==============================] - 45s 172ms/step - loss: 0.3658 - accuracy: 0.8122\n",
      "Epoch 3/10\n",
      "260/260 [==============================] - 46s 176ms/step - loss: 0.2454 - accuracy: 0.8998\n",
      "Epoch 4/10\n",
      "260/260 [==============================] - 43s 164ms/step - loss: 0.1762 - accuracy: 0.9340\n",
      "Epoch 5/10\n",
      "260/260 [==============================] - 45s 173ms/step - loss: 0.1430 - accuracy: 0.9505\n",
      "Epoch 6/10\n",
      "260/260 [==============================] - 42s 161ms/step - loss: 0.1292 - accuracy: 0.9588\n",
      "Epoch 7/10\n",
      "260/260 [==============================] - 41s 157ms/step - loss: 0.1160 - accuracy: 0.9628\n",
      "Epoch 8/10\n",
      "260/260 [==============================] - 41s 158ms/step - loss: 0.1079 - accuracy: 0.9648\n",
      "Epoch 9/10\n",
      "260/260 [==============================] - 39s 151ms/step - loss: 0.0966 - accuracy: 0.9686\n",
      "Epoch 10/10\n",
      "260/260 [==============================] - 39s 150ms/step - loss: 0.0930 - accuracy: 0.9701\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_33 (Conv2D)          (None, 150, 150, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPooli  (None, 75, 75, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 73, 73, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPooli  (None, 36, 36, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPooli  (None, 17, 17, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 18496)             0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                1183808   \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1212513 (4.63 MB)\n",
      "Trainable params: 1212513 (4.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model params\n",
    "input_shape = (150, 150, 3)\n",
    "num_classes = 1 # Number of outputs per input\n",
    "\n",
    "# Model trained on training set\n",
    "model_our_HVoice_SiF_regular = create_cnn_model(input_shape, num_classes)\n",
    "model_our_HVoice_SiF_regular.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model_our_HVoice_SiF_regular.fit(train_generator_HVoice_SiF_Reg, epochs=10)\n",
    "model_our_HVoice_SiF_regular.summary()  # Print model summary\n",
    "\n",
    "# Save model\n",
    "model_dir = 'E:\\DL-project\\Models\\Deep4SNet-Our-HVoice_SiF-Regular.keras'\n",
    "#if not os.path.exists(model_dir):\n",
    "#    os.makedirs(model_dir)\n",
    "model_our_HVoice_SiF_regular.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our - H-Voice + SiF-DeepVC - Filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "262/262 [==============================] - 93s 353ms/step - loss: 0.4789 - accuracy: 0.7277\n",
      "Epoch 2/10\n",
      "262/262 [==============================] - 44s 168ms/step - loss: 0.3295 - accuracy: 0.8356\n",
      "Epoch 3/10\n",
      "262/262 [==============================] - 42s 159ms/step - loss: 0.2371 - accuracy: 0.9039\n",
      "Epoch 4/10\n",
      "262/262 [==============================] - 46s 174ms/step - loss: 0.1793 - accuracy: 0.9310\n",
      "Epoch 5/10\n",
      "262/262 [==============================] - 43s 164ms/step - loss: 0.1431 - accuracy: 0.9493\n",
      "Epoch 6/10\n",
      "262/262 [==============================] - 44s 167ms/step - loss: 0.1235 - accuracy: 0.9569\n",
      "Epoch 7/10\n",
      "262/262 [==============================] - 43s 164ms/step - loss: 0.1160 - accuracy: 0.9629\n",
      "Epoch 8/10\n",
      "262/262 [==============================] - 45s 173ms/step - loss: 0.1058 - accuracy: 0.9641\n",
      "Epoch 9/10\n",
      "262/262 [==============================] - 45s 170ms/step - loss: 0.0982 - accuracy: 0.9682\n",
      "Epoch 10/10\n",
      "262/262 [==============================] - 43s 163ms/step - loss: 0.0913 - accuracy: 0.9703\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_36 (Conv2D)          (None, 150, 150, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPooli  (None, 75, 75, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 73, 73, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPooli  (None, 36, 36, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPooli  (None, 17, 17, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 18496)             0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 64)                1183808   \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1212513 (4.63 MB)\n",
      "Trainable params: 1212513 (4.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model params\n",
    "input_shape = (150, 150, 3)\n",
    "num_classes = 1 # Number of outputs per input\n",
    "\n",
    "# Model trained on training set\n",
    "model_our_HVoice_SiF_filtered = create_cnn_model(input_shape, num_classes)\n",
    "model_our_HVoice_SiF_filtered.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model_our_HVoice_SiF_filtered.fit(train_generator_HVoice_SiF_Filtered, epochs=10)\n",
    "model_our_HVoice_SiF_filtered.summary()  # Print model summary\n",
    "\n",
    "# Save model\n",
    "model_dir = 'E:\\DL-project\\Models\\Deep4SNet-Our-HVoice_SiF-Filtered.keras'\n",
    "#if not os.path.exists(model_dir):\n",
    "#    os.makedirs(model_dir)\n",
    "model_our_HVoice_SiF_filtered.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data - SiF-DeepVC - Regular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original-HVoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model on CPU\n",
    "model_path = 'E:\\DL-project\\Models\\Deep4SNet-Original-HVoice.keras'\n",
    "model_original_HVoice = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 15s 337ms/step - loss: 9.8715 - tp: 663.0000 - fp: 631.0000 - tn: 47.0000 - fn: 16.0000 - accuracy: 0.5232 - precision: 0.5124 - recall: 0.9764 - auc: 0.5421\n",
      "Validation accuracy: 52.32129693031311%\n"
     ]
    }
   ],
   "source": [
    "# Validation Set\n",
    "evaluation_results = model_original_HVoice.evaluate(valid_generator_SiF_reg)\n",
    "print(f'Validation accuracy: {evaluation_results[5] * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 13s 302ms/step - loss: 9.9456 - tp: 672.0000 - fp: 611.0000 - tn: 54.0000 - fn: 13.0000 - accuracy: 0.5378 - precision: 0.5238 - recall: 0.9810 - auc: 0.5567\n",
      "Test accuracy: 53.77777814865112%\n",
      "FPR: 52.37724084177708%\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "evaluation_results = model_original_HVoice.evaluate(test_generator_SiF_reg)\n",
    "print(f'Test accuracy: {evaluation_results[5] * 100}%')\n",
    "\n",
    "# Compute false positive rate (FPR)\n",
    "TP = evaluation_results[0]\n",
    "FP = evaluation_results[1]\n",
    "TN = evaluation_results[2]\n",
    "FN = evaluation_results[3]\n",
    "FPR = FP / (FP + TN)\n",
    "print(f'FPR: {FPR * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 9s 294ms/step - loss: 19.3696 - tp: 0.0000e+00 - fp: 910.0000 - tn: 90.0000 - fn: 0.0000e+00 - accuracy: 0.0900 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00\n",
      "Target Test accuracy: 9.000000357627869%\n",
      "TPR: 17.710227478433822%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test on fake voices built specifically against Deep4SNet by SiF-DeepVC\n",
    "evaluation_results = model_original_HVoice.evaluate(deep4s_generator_SiF_reg)\n",
    "print(f'Target Test accuracy: {evaluation_results[5] * 100}%')\n",
    "\n",
    "# Compute trur positive rate (TPR)\n",
    "TP = evaluation_results[0]\n",
    "FP = evaluation_results[1]\n",
    "TN = evaluation_results[2]\n",
    "FN = evaluation_results[3]\n",
    "TPR = TP / (TP + FN)\n",
    "print(f'TPR: {TPR * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 5s 111ms/step\n",
      "FPR: 95.6390977443609%\n"
     ]
    }
   ],
   "source": [
    "# FPR\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_pred_proba = model_original_HVoice.predict(test_generator_SiF_reg) # ----- CHANGE for Models ---------------\n",
    "\n",
    "# Convert probabilities to binary predictions (0 or 1) based on a threshold\n",
    "threshold = 0.5  # You can adjust this threshold if needed\n",
    "y_pred_binary = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "# Get true labels for the test set\n",
    "y_true = test_generator_SiF_reg.classes # ----- CHANGE for Models ---------------\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_binary)\n",
    "\n",
    "# Extract true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) from the confusion matrix\n",
    "TN = conf_matrix[0, 0]\n",
    "FP = conf_matrix[0, 1]\n",
    "FN = conf_matrix[1, 0]\n",
    "TP = conf_matrix[1, 1]\n",
    "\n",
    "# Compute false positive rate (FPR)\n",
    "FPR = FP / (FP + TN)\n",
    "print(f'FPR: {FPR * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
